@article{Sojoodi2020,
  abstract      = {During recent years, big data explosion and the increase in main memory capacity, on the one hand, and the need for faster data processing, on the other hand, have caused the development of various in-memory processing tools to manage and analyze data. Engaging the speed of the main memory and advantaging data locality, these tools can process a large amount of data with high performance. Apache Ignite, as a distributed in-memory platform, can process massive volumes of data in parallel. Currently, this platform is CPU-based and does not utilize the GPU's processing resources. To address this concern, we introduce Ignite-GPU that uses the GPU's massively parallel processing power. Ignite-GPU handles a number of challenges in integrating GPUs into Ignite and utilizes the GPU's available resources. We have also identified and eliminated time-consuming overheads and used various GPU-specific optimization techniques to improve overall performance. Eventually, we have evaluated Ignite-GPU with the Genetic Algorithm, as a representative of data and compute-intensive algorithms, and gained more than thousands of times speedup in comparison with its CPU version.},
  author        = {Sojoodi, Amirhossein and {Salimi Beni}, Majid and Khunjush, Farshad},
  doi           = {10.1007/s11227-020-03390-z},
  isbn          = {1122702003390},
  issn          = {15730484},
  journal       = {Journal of Supercomputing},
  keywords      = {Apache Ignite,GPU,Genetic{\_}Algorithm,Ignite,In-memory computing,Parallel processing},
  pages         = {1--28},
  publisher     = {Springer US},
  title         = {{Ignite-GPU: a GPU-enabled in-memory computing architecture on clusters}},
  year          = {2020}
}
